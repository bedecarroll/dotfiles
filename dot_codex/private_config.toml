model = "gpt-5.2-codex"
model_reasoning_effort = "high"
tool_output_token_limit = 25000
sandbox_mode = "workspace-write"
# Leave room for native compaction near the 272–273k context window.
# Formula: 273000 - (tool_output_token_limit + 15000)
# With tool_output_token_limit=25000 ⇒ 273000 - (25000 + 15000) = 233000
model_auto_compact_token_limit = 233000

[sandbox_workspace_write]
network_access = true
writable_roots = [
  "/home/bc/.cache",
  "/home/bc/.cargo",
  "/home/bc/.claude",
  "/home/bc/.gemini",
  "/run/user/",
]

[features]
web_search_request = true
skills = true
ghost_commit = false
unified_exec = true
apply_patch_freeform = true
shell_snapshot = true

[tui]
notifications = false

[shell_environment_policy]
inherit = "core"

[mcp_servers.playwriter]
enabled = false
command = "npx"
args = ["playwriter"]

[profiles.yolo]
approval_policy = "never"
sandbox_mode = "danger-full-access"

[profiles.smart-yolo]
approval_policy = "never"
sandbox_mode = "danger-full-access"
model_reasoning_effort = "xhigh"
